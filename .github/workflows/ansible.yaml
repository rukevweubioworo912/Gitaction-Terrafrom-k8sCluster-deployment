name: Deploy Kubernetes Cluster

on:
  push:
    branches:
      - main

jobs:
  ansible_deploy:
    runs-on: ubuntu-latest
    env:
      # üîΩ Hardcoded IPs - Edit these as needed
      MASTER_IP: 13.223.77.209
      WORKER_IPS: '["3.86.11.156", "50.17.11.136"]'
    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y ansible sshpass jq netcat-openbsd
          pip install boto3

      - name: Add SSH Private Key
        run: |
          mkdir -p ~/.ssh
          # üîΩ Paste your private key here (or still use secret just for key)
          echo "${{ secrets.SSH_PRIVATE_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa

      - name: Add known_hosts
        run: |
          ssh-keyscan $MASTER_IP $(echo "$WORKER_IPS" | jq -r '.[]') >> ~/.ssh/known_hosts
          chmod 644 ~/.ssh/known_hosts

      - name: Create Ansible Inventory
        run: |
          echo "[master]" > inventory
          echo "$MASTER_IP ansible_user=ec2-user ansible_ssh_private_key_file=~/.ssh/id_rsa" >> inventory
          echo "[workers]" >> inventory
          for ip in $(echo "$WORKER_IPS" | jq -r '.[]'); do
            echo "$ip ansible_user=ec2-user ansible_ssh_private_key_file=~/.ssh/id_rsa" >> inventory
          done

      - name: Create ansible.cfg
        run: |
          cat > ansible.cfg <<EOF
          [defaults]
          host_key_checking = False
          inventory = ./inventory
          forks = 10
          EOF

      - name: Install Python 3.8 on all nodes
        run: |
          ansible all -m raw -a "test -f /usr/bin/python3.8 || (sudo amazon-linux-extras enable python3.8 && sudo yum install -y python3.8)"

      - name: Update inventory to use Python 3.8
        run: |
          sed -i 's/ansible_ssh_private_key_file/ansible_python_interpreter=\/usr\/bin\/python3.8 ansible_ssh_private_key_file/' inventory

      - name: Run Master Playbook
        run: |
          ansible-playbook -i inventory k8Cluster/Ansible/master.yaml

      - name: Retrieve join command from master output
        id: get_join_cmd
        run: |
          # Ansible master playbook writes this file to localhost
          if [ -f /tmp/kubeadm_join_command.sh ]; then
            JOIN_CMD=$(cat /tmp/kubeadm_join_command.sh)
            echo "JOIN_CMD=$JOIN_CMD" >> $GITHUB_OUTPUT
            echo " Retrieved join command: $JOIN_CMD"
          else
            echo "Failed: /tmp/kubeadm_join_command.sh not found!"
            exit 1
          fi

      - name: Run Worker Playbook
        run: |
          ansible-playbook -i inventory k8Cluster/Ansible/worker.yaml \
            --extra-vars "kubeadm_join_command='${{ steps.get_join_cmd.outputs.JOIN_CMD }}'"

      - name: Verify Kubernetes Nodes are Ready
        run: |
          echo "Waiting for all nodes to be Ready..."
          until ssh -i ~/.ssh/id_rsa -o StrictHostKeyChecking=no ec2-user@$MASTER_IP \
            "kubectl get nodes" | grep -q "Ready"; do
            echo "‚è≥ Nodes not ready yet, waiting 10s..."
            sleep 10
          done
          echo "‚úÖ All nodes are Ready!"
          ssh -i ~/.ssh/id_rsa -o StrictHostKeyChecking=no ec2-user@$MASTER_IP "kubectl get nodes"